# ğŸš€ Ollama + Aider CLI

> **Tu propio "Claude Code" pero 100% gratis, local y multiplataforma**

Este repositorio documenta paso a paso cÃ³mo montar un **CLI de Inteligencia Artificial para desarrollo** usando **Ollama + Aider**, ideal para trabajar directamente sobre proyectos reales (Django, Python, JS, etc.) desde la terminal.

La idea es simple:

* âŒ Sin APIs de pago
* âŒ Sin lÃ­mites artificiales
* âŒ Sin enviar tu cÃ³digo a terceros
* âœ… Todo corre local
* âœ… Funciona directo sobre tu repo

---

## ğŸ§  Â¿QuÃ© es esto?

* **Ollama**: motor local para correr modelos LLM (DeepSeek, LLaMA, etc.)
* **Aider**: CLI que conecta un LLM con tu repositorio Git para leer, analizar y modificar cÃ³digo

Combinados, tienes un **asistente de programaciÃ³n en terminal** que:

* entiende la estructura de tu proyecto
* analiza arquitectura
* propone mejoras
* genera y modifica cÃ³digo

---

## ğŸ§© Requisitos

### Sistema

* Windows 10 / 11 (x64)
* macOS o Linux (tambiÃ©n funciona)
* **RAM recomendada**:

  * mÃ­nimo: 8 GB
  * ideal: 16 GB

### Software

* Git
* Python 3.10+
* Node.js (opcional)

---

## 1ï¸âƒ£ Instalar Ollama

Descarga e instala Ollama desde:

ğŸ‘‰ [https://ollama.com](https://ollama.com)

> En Windows, Ollama se ejecuta como servicio automÃ¡ticamente.

Verifica instalaciÃ³n:

```powershell
ollama list
```

---

## 2ï¸âƒ£ Descargar modelos recomendados

### Modelo ligero (recomendado para empezar)

```powershell
ollama pull deepseek-coder:latest
```

### Modelo mÃ¡s potente (opcional)

```powershell
ollama pull deepseek-coder:6.7b
```

Verifica:

```powershell
ollama list
```

---

## 3ï¸âƒ£ Configurar variable de entorno (IMPORTANTE)

Aider necesita saber dÃ³nde estÃ¡ Ollama:

```powershell
setx OLLAMA_API_BASE http://127.0.0.1:11434
```

Luego:

* cierra todas las terminales
* abre una nueva

Verifica:

```powershell
echo $env:OLLAMA_API_BASE
```

---

## 4ï¸âƒ£ Instalar Aider

Dentro de tu entorno Python (recomendado usar venv):

```powershell
pip install aider-chat
```

Verifica:

```powershell
aider --version
```

---

## 5ï¸âƒ£ Usar Aider en tu proyecto

### 1. Entra al proyecto

```powershell
cd ruta/a/tu/proyecto
```

### 2. Activa el entorno virtual (si aplica)

```powershell
.venv\Scripts\activate
```

### 3. Arranca Aider (configuraciÃ³n estable)

```powershell
aider --model ollama/deepseek-coder:latest --map-tokens 512 --no-auto-commit --no-show-model-warnings
```

---

## ğŸ§ª Prompt inicial recomendado

Usa prompts pequeÃ±os al inicio:

```
lista Ãºnicamente:
- estructura de carpetas principal
- apps detectadas

no hagas cambios
```

Luego puedes avanzar a:

* refactors
* mejoras de arquitectura
* generaciÃ³n de features

---

## ğŸ› ï¸ Comandos Ãºtiles

### Ver modelos activos

```powershell
ollama ps
```

### Probar Ollama directamente

```powershell
ollama run deepseek-coder:latest
```

---

## âš ï¸ Problemas comunes

### âŒ Error: puerto 11434 en uso

```
Only one usage of each socket address...
```

âœ” No es un error
âœ” Ollama ya estÃ¡ corriendo
âœ” NO ejecutes `ollama serve`

---

### âŒ Aider se queda en "Waiting for model"

Soluciones:

* reduce `--map-tokens`
* usa `deepseek-coder:latest`
* cierra apps pesadas

---

## ğŸ“Œ Â¿CuÃ¡ndo usar esto?

âœ” Refactors grandes
âœ” Proyectos locales
âœ” CÃ³digo sensible
âœ” Trabajo offline

Para proyectos pequeÃ±os o rapidez extrema, un CLI cloud (ej: Gemini CLI) puede ser mÃ¡s veloz.

---

## â­ ConclusiÃ³n

Este stack te da:

* un **CLI de IA estilo Claude Code**
* completamente gratis
* control total sobre tu cÃ³digo
* extensible y reutilizable

Ideal para desarrolladores que quieren **potencia sin dependencia de APIs de pago**.

---

## ğŸ§‘â€ğŸ’» Autor

Isaac Haro
Ingeniero en Sistemas Â· Full Stack Â· AutomatizaciÃ³n & Data

---

## ğŸ“„ Licencia

MIT â€” Ãºsalo, modifÃ­calo y compÃ¡rtelo ğŸš€
